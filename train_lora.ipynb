{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-01 18:05:47.028853: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-01 18:05:47.077467: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-01 18:05:47.775545: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "comet_ml is installed but `COMET_API_KEY` is not set.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, BitsAndBytesConfig, AutoTokenizer, TrainingArguments, pipeline, DataCollatorForSeq2Seq\n",
    "from peft import LoraConfig, AutoPeftModelForCausalLM, PeftModel, PeftConfig\n",
    "# from optimum.pipelines import pipeline\n",
    "from trl import SFTTrainer, setup_chat_format\n",
    "import os\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset, DatasetDict, concatenate_datasets\n",
    "import gc\n",
    "from datetime import datetime\n",
    "from tqdm.auto import tqdm, trange\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "## Set Seed\n",
    "set_seed(20240501)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data'\n",
    "train_df = pd.read_csv(os.path.join(data_path,'train_ir.csv'))\n",
    "val_df = pd.read_csv(os.path.join(data_path,'val_ir.csv'))\n",
    "test_df = pd.read_csv(os.path.join(data_path,'test_ir.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>question</th>\n",
       "      <th>domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>건강한 사람이 에너지 균형을 평형 상태로 유지하는 것은 중요합니다. 에너지 균형은 ...</td>\n",
       "      <td>에너지 균형이란 무엇이며, 왜 건강에 중요한가요?</td>\n",
       "      <td>nutrition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>수소, 산소, 질소 가스의 혼합물에서 평균 속도가 가장 빠른 분자는 수소입니다. 수...</td>\n",
       "      <td>수소 분자가 다른 분자들보다 더 빠르게 움직이는 이유는 무엇인가요?</td>\n",
       "      <td>conceptual_physics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>종이와 플라스틱은 재활용 가능한 자원입니다. 중학교 과학 수업에서 우리는 종이와 플...</td>\n",
       "      <td>종이와 플라스틱이 재활용 가능한 이유는 무엇인가요?</td>\n",
       "      <td>ARC_Challenge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>마이애미파랑나비는 남부 플로리다에서 멸종 위기에 처한 종입니다. 이 나비의 개체수 ...</td>\n",
       "      <td>마이애미파랑나비의 주택 건설 증가에 대한 영향은 어떻게 나타나고 있나요?</td>\n",
       "      <td>ARC_Challenge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AIDS에 직면한 민족문화 공동체 연구에 따르면, 한 해 동안 섹스 파트너가 한 명...</td>\n",
       "      <td>성 건강 및 성 문화에 대한 연구에서 발견된 주요 결과는 무엇인가요?</td>\n",
       "      <td>human_sexuality</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              answer  \\\n",
       "0  건강한 사람이 에너지 균형을 평형 상태로 유지하는 것은 중요합니다. 에너지 균형은 ...   \n",
       "1  수소, 산소, 질소 가스의 혼합물에서 평균 속도가 가장 빠른 분자는 수소입니다. 수...   \n",
       "2  종이와 플라스틱은 재활용 가능한 자원입니다. 중학교 과학 수업에서 우리는 종이와 플...   \n",
       "3  마이애미파랑나비는 남부 플로리다에서 멸종 위기에 처한 종입니다. 이 나비의 개체수 ...   \n",
       "4  AIDS에 직면한 민족문화 공동체 연구에 따르면, 한 해 동안 섹스 파트너가 한 명...   \n",
       "\n",
       "                                   question              domain  \n",
       "0               에너지 균형이란 무엇이며, 왜 건강에 중요한가요?           nutrition  \n",
       "1     수소 분자가 다른 분자들보다 더 빠르게 움직이는 이유는 무엇인가요?  conceptual_physics  \n",
       "2              종이와 플라스틱이 재활용 가능한 이유는 무엇인가요?       ARC_Challenge  \n",
       "3  마이애미파랑나비의 주택 건설 증가에 대한 영향은 어떻게 나타나고 있나요?       ARC_Challenge  \n",
       "4    성 건강 및 성 문화에 대한 연구에서 발견된 주요 결과는 무엇인가요?     human_sexuality  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>question</th>\n",
       "      <th>domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>비버는 나무를 베고, 덤불과 관목을 모아 강과 개울에 댐을 만드는 것으로 알려져 있...</td>\n",
       "      <td>비버는 왜 나무를 베고 댐을 만드는 것으로 알려져 있나요?</td>\n",
       "      <td>ARC_Challenge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>아메리카 알리게이터는 플로리다 습지에서 흔하게 발견되는 동물입니다. 그들은 주로 개...</td>\n",
       "      <td>아메리카 알리게이터는 주로 어떤 동물들을 먹나요?</td>\n",
       "      <td>ARC_Challenge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>한 실험을 밀폐 용기를 이용해 실시합니다. 이 실험에서는 용기의 초기 온도가 화씨 ...</td>\n",
       "      <td>실험의 초기 온도와 기압은 각각 얼마입니까?</td>\n",
       "      <td>ARC_Challenge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>알루미늄 염화물과 마그네슘이 반응하여 마그네슘 염화물과 알루미늄이 생성되는 반응식은...</td>\n",
       "      <td>균형 화학 반응식이란 무엇입니까?</td>\n",
       "      <td>ARC_Challenge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>금과 탄소는 에너지를 방출하는 과정에서 서로 다른 방식을 사용합니다. 금은 핵분열을...</td>\n",
       "      <td>금과 탄소가 에너지를 방출하는 데 사용하는 두 가지 서로 다른 과정은 각각 무엇입니까?</td>\n",
       "      <td>conceptual_physics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              answer  \\\n",
       "0  비버는 나무를 베고, 덤불과 관목을 모아 강과 개울에 댐을 만드는 것으로 알려져 있...   \n",
       "1  아메리카 알리게이터는 플로리다 습지에서 흔하게 발견되는 동물입니다. 그들은 주로 개...   \n",
       "2  한 실험을 밀폐 용기를 이용해 실시합니다. 이 실험에서는 용기의 초기 온도가 화씨 ...   \n",
       "3  알루미늄 염화물과 마그네슘이 반응하여 마그네슘 염화물과 알루미늄이 생성되는 반응식은...   \n",
       "4  금과 탄소는 에너지를 방출하는 과정에서 서로 다른 방식을 사용합니다. 금은 핵분열을...   \n",
       "\n",
       "                                           question              domain  \n",
       "0                  비버는 왜 나무를 베고 댐을 만드는 것으로 알려져 있나요?       ARC_Challenge  \n",
       "1                       아메리카 알리게이터는 주로 어떤 동물들을 먹나요?       ARC_Challenge  \n",
       "2                          실험의 초기 온도와 기압은 각각 얼마입니까?       ARC_Challenge  \n",
       "3                                균형 화학 반응식이란 무엇입니까?       ARC_Challenge  \n",
       "4  금과 탄소가 에너지를 방출하는 데 사용하는 두 가지 서로 다른 과정은 각각 무엇입니까?  conceptual_physics  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>question</th>\n",
       "      <th>domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>강한 바람이 삼림 지대의 소나무를 넘어뜨렸을 때, 우거진 숲 지붕에 틈이 생겨 땅에...</td>\n",
       "      <td>강한 바람으로 인해 삼림 지대의 변화가 어떤 과정을 통해 일어나게 되었나요?</td>\n",
       "      <td>ARC_Challenge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>겨울에 습한 공기가 차가운 표면과 접촉하면 결과적으로 서리가 생길 수 있습니다. 이...</td>\n",
       "      <td>서리가 형성되는 데 필요한 두 가지 조건은 무엇이며, 이 조건들이 서로 어떤 관계를...</td>\n",
       "      <td>ARC_Challenge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>망아지는 부모로부터 다음의 모든 형질을 유전적으로 물려받지만, 이에 해당하지 않는 ...</td>\n",
       "      <td>망아지가 부모로부터 유전적으로 물려받는 형질은 무엇인가?</td>\n",
       "      <td>ARC_Challenge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>새의 얇은 부리는 좁은 장소에서 발견되는 먹이를 얻는 데 도움이 될 가능성이 가장 ...</td>\n",
       "      <td>새의 얇은 부리는 어떤 목적으로 사용될 가능성이 높은가?</td>\n",
       "      <td>ARC_Challenge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>지질학자들은 암석의 상대 연대를 결정하기 위해 종종 질량 분석계를 사용합니다. 이 ...</td>\n",
       "      <td>지질학자들이 암석의 상대 연대를 결정하는 데 질량 분석계가 어떻게 사용됩니까?</td>\n",
       "      <td>ARC_Challenge</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              answer  \\\n",
       "0  강한 바람이 삼림 지대의 소나무를 넘어뜨렸을 때, 우거진 숲 지붕에 틈이 생겨 땅에...   \n",
       "1  겨울에 습한 공기가 차가운 표면과 접촉하면 결과적으로 서리가 생길 수 있습니다. 이...   \n",
       "2  망아지는 부모로부터 다음의 모든 형질을 유전적으로 물려받지만, 이에 해당하지 않는 ...   \n",
       "3  새의 얇은 부리는 좁은 장소에서 발견되는 먹이를 얻는 데 도움이 될 가능성이 가장 ...   \n",
       "4  지질학자들은 암석의 상대 연대를 결정하기 위해 종종 질량 분석계를 사용합니다. 이 ...   \n",
       "\n",
       "                                            question         domain  \n",
       "0         강한 바람으로 인해 삼림 지대의 변화가 어떤 과정을 통해 일어나게 되었나요?  ARC_Challenge  \n",
       "1  서리가 형성되는 데 필요한 두 가지 조건은 무엇이며, 이 조건들이 서로 어떤 관계를...  ARC_Challenge  \n",
       "2                    망아지가 부모로부터 유전적으로 물려받는 형질은 무엇인가?  ARC_Challenge  \n",
       "3                    새의 얇은 부리는 어떤 목적으로 사용될 가능성이 높은가?  ARC_Challenge  \n",
       "4        지질학자들이 암석의 상대 연대를 결정하는 데 질량 분석계가 어떻게 사용됩니까?  ARC_Challenge  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['answer', 'question', 'domain'],\n",
       "         num_rows: 2912\n",
       "     })\n",
       "     valid: Dataset({\n",
       "         features: ['answer', 'question', 'domain'],\n",
       "         num_rows: 434\n",
       "     })\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['answer', 'question', 'domain'],\n",
       "     num_rows: 926\n",
       " }))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "valid_dataset = Dataset.from_pandas(val_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'valid': valid_dataset,\n",
    "    })\n",
    "dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27a87202ddfd4279b558ae9c04b1dc3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2912 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "594cd68af6e3458aa10c6bf243504f80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/434 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efb2bb45ed56416bbf832ba5b69fe516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/926 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['messages'],\n",
       "         num_rows: 2912\n",
       "     })\n",
       "     valid: Dataset({\n",
       "         features: ['messages'],\n",
       "         num_rows: 434\n",
       "     })\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['answer', 'domain', 'messages'],\n",
       "     num_rows: 926\n",
       " }))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 프롬프트 작성\n",
    "system_message = \"You are a science question answerer. Users will ask you questions about science in Korean and you will generate an answer about science in Korean.\" \n",
    "\n",
    "def create_conversation(sample, is_test = False):\n",
    "  return {\n",
    "    \"messages\": [\n",
    "      {\"role\": \"system\", \"content\": system_message},\n",
    "      {\"role\": \"user\", \"content\": sample[\"question\"]},\n",
    "      {\"role\": \"assistant\", \"content\": sample[\"answer\"]}\n",
    "    ]\n",
    "  } if not is_test else {\n",
    "    \"messages\": [\n",
    "      {\"role\": \"system\", \"content\": system_message},\n",
    "      {\"role\": \"user\", \"content\": sample[\"question\"]},\n",
    "    ]\n",
    "  }\n",
    "dataset = dataset.map(create_conversation, remove_columns=['question', 'answer', 'domain'], batched=False)\n",
    "# Test 데이터에는 fname이 정답과 같이 들어가야하기 때문에 지우지 않음\n",
    "test_dataset = test_dataset.map(lambda sample: create_conversation(sample, is_test=True), remove_columns=['question'], batched=False)\n",
    "dataset, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "352"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"./results_ir\"\n",
    "model_name =\"beomi/OPEN-SOLAR-KO-10.7B\" #\"google/gemma-7b\", \"beomi/OPEN-SOLAR-KO-10.7B\", \"beomi/open-llama-2-ko-7b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edf44d4f21d94be8a61dec1786b5c06e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# 모델 경량화\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "# Foundation 모델 로드\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    use_cache=False,\n",
    "    token=True,\n",
    ")\n",
    "\n",
    "model.config.pretraining_tp = 1 \n",
    "\n",
    "# 토크나이저 로드\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.padding_side = 'right'\n",
    "\n",
    "# conversational AI 태스크를 수행하도록 변환\n",
    "model, tokenizer = setup_chat_format(model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/demyank/anaconda3/lib/python3.11/site-packages/datasets/table.py:1395: FutureWarning: promote has been superseded by mode='default'.\n",
      "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
      "/home/demyank/anaconda3/lib/python3.11/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max source length: 840\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "len_tokens = []\n",
    "for data in concatenate_datasets([dataset[\"train\"], dataset[\"valid\"]]):\n",
    "    len_tokens.append(len(tokenizer.apply_chat_template(data[\"messages\"])))\n",
    "plt.hist(len_tokens, bins=50)\n",
    "plt.show()\n",
    "\n",
    "len_tokens.sort(reverse=True)\n",
    "print(f\"Max source length: {max(len_tokens)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 328"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3346 103\n"
     ]
    }
   ],
   "source": [
    "# (데이터 개수, 데이터 중 328 토큰 이상인 데이터 개수)\n",
    "print(len(len_tokens), len_tokens.index(cutoff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8d6f77d0e124451b8bc3c6e7a06b284",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/2912 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12b4b9981b9049208d1e4e0d80e3101e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/434 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 토큰 수가 512개 미만인 데이터만 필터링하여 학습\n",
    "dataset = dataset.filter(lambda sample : len(tokenizer.apply_chat_template(sample[\"messages\"])) < cutoff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default : r = 8, lora_alpha = 8\n",
    "# 적절한 수는 아직 연구중인 단계.\n",
    "# 다만, 오버피팅 되지 않도록 적절한 dropout값은 주는게 나음.\n",
    "peft_config = LoraConfig(\n",
    "        r=256, # default = 8\n",
    "        lora_alpha=128, # default = 8\n",
    "        lora_dropout=0.05,\n",
    "        bias=\"none\",\n",
    "        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"], # \"all-linear\" 라고만 입력하면, 모든 리니어 레이어가 타겟이 됨.\n",
    "        task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_PROJECT\"] = \"scientific qa\"  # name your W&B project\n",
    "os.environ[\"WANDB_LOG_MODEL\"] = \"checkpoint\"  # log all model checkpoints\n",
    "\n",
    "# 학습 파라미터.\n",
    "args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=8,          # 학습시 배치 사이즈\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=8,          # 메모리가 작아 배치사이즈가 적을때 그라디언트를 합쳐서 같은 효과를 내도록 함.\n",
    "    eval_accumulation_steps=8,\n",
    "    gradient_checkpointing=True,            # memory 아끼기 위해서 사용.\n",
    "    optim=\"adamw_torch_fused\",              # fused adamw optimizer 사용.\n",
    "    logging_steps=5,                       # 학습 한번 돌려보고, 적절한 시간에 맞춰 설정.\n",
    "    logging_strategy='steps',\n",
    "    eval_steps=5,                          # validation loss를 보고 싶다면 설정,\n",
    "    evaluation_strategy='steps',\n",
    "    save_strategy=\"steps\",                  # checkpoint 저장방식. 추후, trainer.train(resume_from_checkpoint=True) 를 이용해 이어서 학습 가능.\n",
    "    save_steps=10,\n",
    "    save_total_limit=2,                     # 스토리지 꽉차니 최대 리밋 설정해주세요.\n",
    "    learning_rate=4e-5,                     # QLoRA 논문에서 사용한 learning rate 참고\n",
    "    bf16=True,                              # bfloat16\n",
    "    tf32=True,                              # tf32\n",
    "    max_grad_norm=0.3,                      # QLoRA 논문에서 사용한 max gradient norm 참고\n",
    "    warmup_ratio=0.1,                       # QLoRA 논문에서 사용한 warmup ratio 참고\n",
    "    lr_scheduler_type=\"cosine\",             # cosine scheduler. 스케쥴러 사용시 성능이 좋다는 실험결과가 있음.\n",
    "    report_to=\"wandb\",  # Set to 'wandb' to use Weights & Biases\n",
    "    run_name=f'trial_{datetime.now().strftime(\"%Y-%m-%d_%H-%M\")}',  # Optional: give a name to the wandb run\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bb368dd2c8642059743590ae6fe6e61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "861f5bd417424b08926749c0259f4049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/demyank/anaconda3/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdemyank88\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/demyank/tutorial/upstage/competition/upstage-ai-final-ir2/wandb/run-20240501_170048-0xtmhx7j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/demyank88/scientific%20qa/runs/0xtmhx7j' target=\"_blank\">trial_2024-05-01_17-00</a></strong> to <a href='https://wandb.ai/demyank88/scientific%20qa' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/demyank88/scientific%20qa' target=\"_blank\">https://wandb.ai/demyank88/scientific%20qa</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/demyank88/scientific%20qa/runs/0xtmhx7j' target=\"_blank\">https://wandb.ai/demyank88/scientific%20qa/runs/0xtmhx7j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/demyank/anaconda3/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "The input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.bfloat16.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 13:39, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.425800</td>\n",
       "      <td>1.776386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.514100</td>\n",
       "      <td>1.298132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.213900</td>\n",
       "      <td>1.213395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.194900</td>\n",
       "      <td>1.186632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.170600</td>\n",
       "      <td>1.179827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./results_ir/checkpoint-10)... Done. 11.1s\n",
      "/home/demyank/anaconda3/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./results_ir/checkpoint-20)... Done. 9.9s\n",
      "/home/demyank/anaconda3/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/demyank/anaconda3/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=27, training_loss=1.4801408538111933, metrics={'train_runtime': 846.7532, 'train_samples_per_second': 2.063, 'train_steps_per_second': 0.032, 'total_flos': 3.967554454290432e+16, 'train_loss': 1.4801408538111933, 'epoch': 0.99})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq_length = cutoff\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"valid\"],\n",
    "    peft_config=peft_config,\n",
    "    max_seq_length=max_seq_length,\n",
    "    tokenizer=tokenizer,\n",
    "    #compute_metrics = lambda pred: compute_metrics(tokenizer, pred),\n",
    "    #preprocess_logits_for_metrics = preprocess_logits_for_metrics,\n",
    "    packing=True,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and tokenizer\n",
    "model_name = \"beomi/OPEN-SOLAR-KO-10.7B\"\n",
    "checkpoint_path = \"./results_ir/checkpoint-20\"\n",
    "\n",
    "# Configuration for model quantization\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the base model\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    use_cache=False,\n",
    "    token=True\n",
    ")\n",
    "\n",
    "# Load the fine-tuned PeftModel\n",
    "model = PeftModel.from_pretrained(model=base_model, model_id=checkpoint_path, device_map='auto')\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ### Instruction: 나무의 분류에 대해 조사해 보기 위한 방법은? ### Answer: 분류는 생물학에서 사용되는 중요한 개념 중 하나입니다. 생물을 분류하는 것은 생물의 구조, 기능, 생태학적 역할 등을 고려하여 이루어집니다. 나무를 분류하기 위해서는 먼저 나무가 속한 과를 파악해야 합니다. 과는 유사한 특징을 공유하는 식물들의 그룹을 의미합니다. 예를 들어, 과일나무는 과실나무과에 속하며, 이 과에는 사과, 배, 복숭아 등의 과일이 속해 있습니다. 다음으로, 나무는 종으로 분류됩니다. 종은 같은 속의 다른 식물들과 구별되는 고유한 특성을 갖는 식물들을 나타냅니다. 이러한 종들은 서로 다른 유전적 특징과 생태\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example input text\n",
    "input_text = \"### Instruction: 나무의 분류에 대해 조사해 보기 위한 방법은? ### Answer:\"\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Generating output without pipeline\n",
    "outputs = model.generate(\n",
    "    input_ids=inputs['input_ids'],\n",
    "    attention_mask=inputs['attention_mask'],\n",
    "    max_length=160,\n",
    "    num_beams=3,\n",
    "    no_repeat_ngram_size=2,\n",
    "    early_stopping=True,\n",
    "    do_sample=True\n",
    ")\n",
    "\n",
    "# Decode the generated tokens to a string\n",
    "answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(\"Answer:\", answer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
